import pandas as pd
import os, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import re
from rich.panel import Panel
from rich.console import Console
import autocorrect_py as autocorrect

console = Console()

CLEANED_CHUNKS_FILE = 'output/log/cleaned_chunks.xlsx'
TRANSLATION_RESULTS_FOR_SUBTITLES_FILE = 'output/log/translation_results_for_subtitles.xlsx'
TRANSLATION_RESULTS_REMERGED_FILE = 'output/log/translation_results_remerged.xlsx'

OUTPUT_DIR = 'output'
AUDIO_OUTPUT_DIR = 'output/audio'

SUBTITLE_OUTPUT_CONFIGS = [ 
    ('src.srt', ['Source']),
    ('trans.srt', ['Translation']),
    ('src_trans.srt', ['Source', 'Translation']),
    ('trans_src.srt', ['Translation', 'Source'])
]

AUDIO_SUBTITLE_OUTPUT_CONFIGS = [
    ('src_subs_for_audio.srt', ['Source']),
    ('trans_subs_for_audio.srt', ['Translation'])
]

def convert_to_srt_format(start_time, end_time):
    """Convert time (in seconds) to the format: hours:minutes:seconds,milliseconds"""
    def seconds_to_hmsm(seconds):
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        seconds = seconds % 60
        milliseconds = int(seconds * 1000) % 1000
        return f"{hours:02d}:{minutes:02d}:{int(seconds):02d},{milliseconds:03d}"

    start_srt = seconds_to_hmsm(start_time)
    end_srt = seconds_to_hmsm(end_time)
    return f"{start_srt} --> {end_srt}"

def remove_punctuation(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'[^\w\s]', '', text)
    return text.strip()

def show_difference(str1, str2):
    """æ˜¾ç¤ºä¸¤ä¸ªå­—ç¬¦ä¸²ä¹‹é—´çš„å·®å¼‚ä½ç½®"""
    # è·å–ä¸¤ä¸ªå­—ç¬¦ä¸²ä¸­è¾ƒçŸ­çš„é•¿åº¦
    min_len = min(len(str1), len(str2))
    
    # åˆå§‹åŒ–ä¸€ä¸ªå­˜å‚¨å·®å¼‚ä½ç½®çš„åˆ—è¡¨
    diff_positions = []
    
    # é€å­—ç¬¦æ¯”è¾ƒï¼Œæ‰¾å‡ºä¸åŒçš„ä½ç½®
    for i in range(min_len):
        if str1[i] != str2[i]:
            diff_positions.append(i)
    
    # å¦‚æœä¸¤ä¸ªå­—ç¬¦ä¸²é•¿åº¦ä¸åŒï¼Œå°†å‰©ä½™çš„ä½ç½®ä¹Ÿæ ‡è®°ä¸ºå·®å¼‚
    if len(str1) != len(str2):
        diff_positions.extend(range(min_len, max(len(str1), len(str2))))
    
    # æ‰“å°æœŸæœ›çš„å¥å­
    print("Difference positions:")
    print(f"Expected sentence: {str1}")
    
    # æ‰“å°å®é™…åŒ¹é…çš„å¥å­
    print(f"Actual match: {str2}")
    
    # æ‰“å°å¸¦æœ‰å·®å¼‚æ ‡è®°çš„ä½ç½®æ ‡è®°
    print("Position markers: " + "".join("^" if i in diff_positions else " " for i in range(max(len(str1), len(str2)))))
    
    # æ‰“å°å·®å¼‚çš„ç´¢å¼•ä½ç½®
    print(f"Difference indices: {diff_positions}")

def get_sentence_timestamps(df_words, df_sentences):
    """
    è·å–å¥å­çš„æ—¶é—´æˆ³
    
    å¼‚å¸¸æŠ›å‡ºæ¡ä»¶ï¼š
    1. å½“æ— æ³•åœ¨å®Œæ•´å•è¯å­—ç¬¦ä¸²ä¸­æ‰¾åˆ°åŒ¹é…çš„å¥å­æ—¶
       - å¯èƒ½åŸå› ï¼š
         a. è¾“å…¥çš„å•è¯åˆ—è¡¨å’Œå¥å­åˆ—è¡¨ä¸åŒ¹é…
         b. å¥å­æ¸…ç†åçš„æ–‡æœ¬ä¸å•è¯å­—ç¬¦ä¸²ä¸å®Œå…¨å¯¹åº”
         c. å­˜åœ¨ç‰¹æ®Šå­—ç¬¦æˆ–æ ¼å¼å¯¼è‡´åŒ¹é…å¤±è´¥
    
    2. å…·ä½“å¼‚å¸¸åœºæ™¯ï¼š
       - å¥å­ä¸­åŒ…å«ç‰¹æ®Šæ ‡è®°æˆ–æ ¼å¼
       - å•è¯åˆ—è¡¨å’Œå¥å­åˆ—è¡¨çš„æ–‡æœ¬å¤„ç†ä¸ä¸€è‡´
       - è¾“å…¥æ•°æ®å­˜åœ¨é¢„æœŸå¤–çš„æ–‡æœ¬æ ¼å¼
    
    å¼‚å¸¸å¤„ç†ï¼š
    - æ‰“å°æœªåŒ¹é…å¥å­çš„è¯¦ç»†ä¿¡æ¯
    - ä½¿ç”¨ show_difference æ˜¾ç¤ºåŒ¹é…å¤±è´¥çš„å…·ä½“ä½ç½®
    - æŠ›å‡º ValueErrorï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    """
    # åˆå§‹åŒ–å­˜å‚¨æ—¶é—´æˆ³çš„åˆ—è¡¨
    time_stamp_list = []
    
    # æ„å»ºå®Œæ•´çš„å•è¯å­—ç¬¦ä¸²å’Œä½ç½®æ˜ å°„
    full_words_str = ''
    position_to_word_idx = {}
    
    # éå†æ‰€æœ‰å•è¯ï¼Œæ„å»ºå®Œæ•´çš„å•è¯å­—ç¬¦ä¸²å¹¶å»ºç«‹ä½ç½®æ˜ å°„
    for idx, word in enumerate(df_words['text']):
        # æ¸…ç†å•è¯ï¼Œå»é™¤æ ‡ç‚¹å’Œè½¬æ¢ä¸ºå°å†™
        clean_word = remove_punctuation(word.lower())
        
        # è®°å½•å½“å‰å•è¯åœ¨å®Œæ•´å­—ç¬¦ä¸²ä¸­çš„èµ·å§‹ä½ç½®
        start_pos = len(full_words_str)
        
        # å°†æ¸…ç†åçš„å•è¯æ·»åŠ åˆ°å®Œæ•´å­—ç¬¦ä¸²ä¸­
        full_words_str += clean_word
        
        # ä¸ºå®Œæ•´å­—ç¬¦ä¸²ä¸­çš„æ¯ä¸ªå­—ç¬¦å»ºç«‹ä½ç½®åˆ°å•è¯ç´¢å¼•çš„æ˜ å°„
        for pos in range(start_pos, len(full_words_str)):
            position_to_word_idx[pos] = idx
    
    # åˆå§‹åŒ–å½“å‰æœç´¢ä½ç½®
    current_pos = 0
    
    # éå†æ¯ä¸ªå¥å­
    for idx, sentence in df_sentences['Source'].items():
        # æ¸…ç†å¥å­ï¼Œå»é™¤æ ‡ç‚¹ã€ç©ºæ ¼å’Œç‰¹æ®Šæ ‡è®°
        clean_sentence = remove_punctuation(sentence.lower()).replace(" ", "")
        
        # è·å–æ¸…ç†åå¥å­çš„é•¿åº¦
        sentence_len = len(clean_sentence)
        
        # æ ‡è®°æ˜¯å¦æ‰¾åˆ°åŒ¹é…
        match_found = False
        
        # åœ¨å®Œæ•´å•è¯å­—ç¬¦ä¸²ä¸­æœç´¢åŒ¹é…çš„å¥å­
        while current_pos <= len(full_words_str) - sentence_len:
            # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„å¥å­
            if full_words_str[current_pos:current_pos+sentence_len] == clean_sentence:
                # è·å–å¥å­èµ·å§‹å’Œç»“æŸå•è¯çš„ç´¢å¼•
                start_word_idx = position_to_word_idx[current_pos]
                end_word_idx = position_to_word_idx[current_pos + sentence_len - 1]
                
                # å°†å¥å­çš„èµ·å§‹å’Œç»“æŸæ—¶é—´æˆ³æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                time_stamp_list.append((float(df_words['start'][start_word_idx]), float(df_words['end'][end_word_idx])))
                
                # æ›´æ–°å½“å‰æœç´¢ä½ç½®
                current_pos += sentence_len
                
                # æ ‡è®°æ‰¾åˆ°åŒ¹é…
                match_found = True
                break
            
            # å¦‚æœæœªæ‰¾åˆ°åŒ¹é…ï¼Œç§»åŠ¨æœç´¢ä½ç½®
            current_pos += 1
            
            # å¦‚æœä»æœªæ‰¾åˆ°åŒ¹é…ï¼ŒæŠ›å‡ºå¼‚å¸¸å¹¶æ˜¾ç¤ºå·®å¼‚
            if not match_found:
                print(f"\nâš ï¸ Warning: No exact match found for sentence: {sentence}")
                show_difference(clean_sentence, full_words_str[current_pos:current_pos+len(clean_sentence)])
                print("\nOriginal sentence:", df_sentences['Source'][idx])
                print(f"\nä¸åŒ¹é…çš„å¥å­: {sentence}")
                print(f"ä¸åŒ¹é…çš„å­—å¹•: {df_sentences['Translation'][idx]}")
                #raise ValueError("â No match found for sentence.")
    
    # è¿”å›æ—¶é—´æˆ³åˆ—è¡¨
    return time_stamp_list

def align_timestamp(df_text, df_translate, subtitle_output_configs: list, output_dir: str, for_display: bool = True):
    """Align timestamps and add a new timestamp column to df_translate"""
    df_trans_time = df_translate.copy()

    # Assign an ID to each word in df_text['text'] and create a new DataFrame
    words = df_text['text'].str.split(expand=True).stack().reset_index(level=1, drop=True).reset_index()
    words.columns = ['id', 'word']
    words['id'] = words['id'].astype(int)

    # Process timestamps â°
    time_stamp_list = get_sentence_timestamps(df_text, df_translate)
    df_trans_time['timestamp'] = time_stamp_list
    df_trans_time['duration'] = df_trans_time['timestamp'].apply(lambda x: x[1] - x[0])

    # Remove gaps ğŸ•³ï¸
    for i in range(len(df_trans_time)-1):
        delta_time = df_trans_time.loc[i+1, 'timestamp'][0] - df_trans_time.loc[i, 'timestamp'][1]
        if 0 < delta_time < 1:
            df_trans_time.at[i, 'timestamp'] = (df_trans_time.loc[i, 'timestamp'][0], df_trans_time.loc[i+1, 'timestamp'][0])

    # Convert start and end timestamps to SRT format
    df_trans_time['timestamp'] = df_trans_time['timestamp'].apply(lambda x: convert_to_srt_format(x[0], x[1]))

    # Polish subtitles: replace punctuation in Translation if for_display
    if for_display:
        df_trans_time['Translation'] = df_trans_time['Translation'].apply(lambda x: re.sub(r'[ï¼Œã€‚]', ' ', x).strip())

    # Output subtitles ğŸ“œ
    def generate_subtitle_string(df, columns):
        return ''.join([f"{i+1}\n{row['timestamp']}\n{row[columns[0]].strip()}\n{row[columns[1]].strip() if len(columns) > 1 else ''}\n\n" for i, row in df.iterrows()]).strip()

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        for filename, columns in subtitle_output_configs:
            subtitle_str = generate_subtitle_string(df_trans_time, columns)
            with open(os.path.join(output_dir, filename), 'w', encoding='utf-8') as f:
                f.write(subtitle_str)
    
    return df_trans_time

# âœ¨ Beautify the translation
def clean_translation(x):
    """
    æ¸…ç†ç¿»è¯‘æ–‡æœ¬çš„å‡½æ•°ï¼Œç”¨äºç¾åŒ–å’Œè§„èŒƒåŒ–ç¿»è¯‘ç»“æœ

    å‚æ•°:
    x (str): è¾“å…¥çš„ç¿»è¯‘æ–‡æœ¬

    å¤„ç†é€»è¾‘:
    1. å¦‚æœè¾“å…¥ä¸ºç©ºæˆ–NaNï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
    2. å»é™¤æ–‡æœ¬å¼€å¤´å’Œç»“å°¾çš„ä¸­æ–‡å¥å·å’Œé€—å·
    3. ä½¿ç”¨ autocorrect è¿›è¡Œæ–‡æœ¬æ ¼å¼åŒ–å’Œè‡ªåŠ¨çº æ­£

    è¿”å›:
    str: æ¸…ç†å’Œç¾åŒ–åçš„ç¿»è¯‘æ–‡æœ¬
    """
    if pd.isna(x):
        return ''
    cleaned = str(x).strip('ã€‚').strip('ï¼Œ')
    return autocorrect.format(cleaned)


def validate_and_clean_translation_results(cleaned_chunks, translation_results):
    """
    éªŒè¯å¹¶æ¸…ç†ç¿»è¯‘ç»“æœï¼Œç¡®ä¿Sourceä¸­çš„å•è¯å­˜åœ¨ä¸”é¡ºåºä¸cleaned_chunksä¸­textåˆ—ä¸€è‡´
    
    å‚æ•°:
    cleaned_chunks (pandas.DataFrame): æ¸…ç†åçš„å—æ•°æ®
    translation_results (pandas.DataFrame): ç¿»è¯‘ç»“æœæ•°æ®
    
    è¿”å›:
    pandas.DataFrame: æ¸…ç†åçš„ç¿»è¯‘ç»“æœ
    """
    if cleaned_chunks is None or translation_results is None:
        print("è¾“å…¥æ•°æ®ä¸èƒ½ä¸ºç©º")
        return None
    
    # åˆå¹¶æ‰€æœ‰textåˆ—çš„å†…å®¹ä¸ºä¸€ä¸ªå¤§å­—ç¬¦ä¸²
    all_text = ' '.join(cleaned_chunks['text'].dropna().astype(str))
    
    # åˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameæ¥å­˜å‚¨æ¸…ç†åçš„ç¿»è¯‘ç»“æœ
    cleaned_translation_results = translation_results.copy()
    
    def clean_source(source):
        # å°†sourceæ‹†åˆ†ä¸ºå•è¯
        source_words = str(source).split()
        
        # è¿‡æ»¤å‡ºå­˜åœ¨äºall_textä¸­çš„å•è¯
        valid_words = [word for word in source_words if word in all_text]
        
        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆå•è¯ï¼Œè¿”å›åŸå§‹source
        if not valid_words:
            return source
        
        # è¿”å›æœ‰æ•ˆå•è¯ç»„æˆçš„å­—ç¬¦ä¸²
        return ' '.join(valid_words)
    
    # å¯¹æ¯ä¸€è¡Œçš„Sourceåˆ—è¿›è¡Œå¤„ç†
    cleaned_translation_results['Source'] = cleaned_translation_results['Source'].apply(clean_source)
    
    # ä¿å­˜æ¸…ç†åçš„ç»“æœ
    output_path = 'output/log/cleaned_translation_results.xlsx'
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    cleaned_translation_results.to_excel(output_path, index=False)
    print(f"å·²ä¿å­˜æ¸…ç†åçš„ç¿»è¯‘ç»“æœåˆ° {output_path}")
    
    return cleaned_translation_results


def align_timestamp_main():
    df_text = pd.read_excel(CLEANED_CHUNKS_FILE)
    df_text['text'] = df_text['text'].str.strip('"').str.strip()
    df_translate = pd.read_excel(TRANSLATION_RESULTS_FOR_SUBTITLES_FILE)
    df_translate['Translation'] = df_translate['Translation'].apply(clean_translation)
    df_translate['Source'] = df_translate['Source'].apply(clean_translation)
    df_translate= validate_and_clean_translation_results(df_text,df_translate)
    align_timestamp(df_text, df_translate, SUBTITLE_OUTPUT_CONFIGS, OUTPUT_DIR)
    console.print(Panel("[bold green]ğŸ‰ğŸ“ Subtitles generation completed! Please check in the `output` folder ğŸ‘€[/bold green]"))

    # for audio
    df_translate_for_audio = pd.read_excel(TRANSLATION_RESULTS_REMERGED_FILE) # use remerged file to avoid unmatched lines when dubbing
    df_translate_for_audio['Translation'] = df_translate_for_audio['Translation'].apply(clean_translation)
    
    # åŒæ ·å¤„ç†éŸ³é¢‘å­—å¹•çš„ Source åˆ—
    df_translate_for_audio = clean_source_column(df_text, df_translate_for_audio)
    
    align_timestamp(df_text, df_translate_for_audio, AUDIO_SUBTITLE_OUTPUT_CONFIGS, AUDIO_OUTPUT_DIR)
    console.print(Panel("[bold green]ğŸ‰ğŸ“ Audio subtitles generation completed! Please check in the `output/audio` folder ğŸ‘€[/bold green]"))



if __name__ == '__main__':
    align_timestamp_main()
